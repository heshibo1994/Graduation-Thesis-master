
@inproceedings{BrachmannUncertaintyDriven6DPose2016,
  title = {Uncertainty-{{Driven 6D Pose Estimation}} of {{Objects}} and {{Scenes}} from a {{Single RGB Image}}},
  isbn = {978-1-4673-8851-1},
  doi = {10.1109/CVPR.2016.366},
  abstract = {In recent years, the task of estimating the 6D pose of object instances and complete scenes, i.e. camera localization, from a single input image has received considerable attention. Consumer RGB-D cameras have made this feasible, even for difficult, texture-less objects and scenes. In this work, we show that a single RGB image is sufficient to achieve visually convincing results. Our key concept is to model and exploit the uncertainty of the system at all stages of the processing pipeline. The uncertainty comes in the form of continuous distributions over 3D object coordinates and discrete distributions over object labels. We give three technical contributions. Firstly, we develop a regularized, auto-context regression framework which iteratively reduces uncertainty in object coordinate and object label predictions. Secondly, we introduce an efficient way to marginalize object coordinate distributions over depth. This is necessary to deal with missing depth information. Thirdly, we utilize the distributions over object labels to detect multiple objects simultaneously with a fixed budget of RANSAC hypotheses. We tested our system for object pose estimation and camera localization on commonly used data sets. We see a major improvement over competing systems.},
  language = {en},
  publisher = {{IEEE}},
  author = {Brachmann, Eric and Michel, Frank and Krull, Alexander and Yang, Michael Ying and Gumhold, Stefan and Rother, Carsten},
  month = jun,
  year = {2016},
  pages = {3364-3372},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\ZEHCXU6W\\Brachmann 等。 - 2016 - Uncertainty-Driven 6D Pose Estimation of Objects a.pdf}
}

@article{LoweDistinctiveimagefeatures2004,
  title = {Distinctive Image Features from Scale-Invariant Keypoints},
  volume = {60},
  number = {2},
  journal = {International journal of computer vision},
  author = {Lowe, David G.},
  year = {2004},
  pages = {91--110},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\TARYEQ23\\BVISI.0000029664.99615.html}
}

@article{TuAutocontextitsapplication2010,
  title = {Auto-Context and Its Application to High-Level Vision Tasks and 3d Brain Image Segmentation},
  volume = {32},
  number = {10},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author = {Tu, Zhuowen and Bai, Xiang},
  year = {2010},
  pages = {1744--1757},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\8UAMEYPC\\Tu 和 Bai - 2010 - Auto-context and its application to high-level vis.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\C3Z98RZG\\5342426.html}
}

@inproceedings{BrachmannLearning6dobject2014,
  title = {Learning 6d Object Pose Estimation Using 3d Object Coordinates},
  booktitle = {European Conference on Computer Vision},
  publisher = {{Springer}},
  author = {Brachmann, Eric and Krull, Alexander and Michel, Frank and Gumhold, Stefan and Shotton, Jamie and Rother, Carsten},
  year = {2014},
  pages = {536--551},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\ECKSUAUB\\Brachmann 等。 - 2014 - Learning 6d object pose estimation using 3d object.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\STQTDDA5\\978-3-319-10605-2_35.html}
}

@inproceedings{ShottonScenecoordinateregression2013,
  title = {Scene Coordinate Regression Forests for Camera Relocalization in {{RGB}}-{{D}} Images},
  booktitle = {Computer {{Vision}} and {{Pattern Recognition}} ({{CVPR}}), 2013 {{IEEE Conference}} On},
  publisher = {{IEEE}},
  author = {Shotton, Jamie and Glocker, Ben and Zach, Christopher and Izadi, Shahram and Criminisi, Antonio and Fitzgibbon, Andrew},
  year = {2013},
  pages = {2930--2937},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\UG4KGDCD\\Shotton 等。 - 2013 - Scene coordinate regression forests for camera rel.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\XEGWDU2X\\Shotton 等。 - 2013 - Scene coordinate regression forests for camera rel.pdf}
}

@inproceedings{TaylorvitruvianmanifoldInferring2012,
  title = {The Vitruvian Manifold: {{Inferring}} Dense Correspondences for One-Shot Human Pose Estimation},
  shorttitle = {The Vitruvian Manifold},
  booktitle = {Computer {{Vision}} and {{Pattern Recognition}} ({{CVPR}}), 2012 {{IEEE Conference}} On},
  publisher = {{IEEE}},
  author = {Taylor, Jonathan and Shotton, Jamie and Sharp, Toby and Fitzgibbon, Andrew},
  year = {2012},
  pages = {103--110},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\Q6KB8RMP\\Taylor 等。 - 2012 - The vitruvian manifold Inferring dense correspond.pdf}
}

@inproceedings{YeFastHierarchicalTemplate2016,
  title = {Fast {{Hierarchical Template Matching Strategy}} for {{Real}}-{{Time Pose Estimation}} of {{Texture}}-{{Less Objects}}},
  booktitle = {International {{Conference}} on {{Intelligent Robotics}} and {{Applications}}},
  publisher = {{Springer}},
  author = {Ye, Chaoqiang and Li, Kai and Jia, Lei and Zhuang, Chungang and Xiong, Zhenhua},
  year = {2016},
  pages = {225--236}
}

@misc{albertoprettod2co,
  title = {Alberto\_pretto / D2co},
  abstract = {Git repository hosted by Bitbucket.},
  language = {en},
  howpublished = {https://bitbucket.org/alberto\_pretto/d2co}
}

@inproceedings{ImperoliCOFastRobust2015,
  title = {D \$ \$\^\$\{\$2\$\}\$ \$ \$ {{CO}}: {{Fast}} and {{Robust Registration}} of {{3D Textureless Objects Using}} the {{Directional Chamfer Distance}}},
  shorttitle = {D \$ \$\^\$\{\$2\$\}\$ \$ \$ {{CO}}},
  booktitle = {International {{Conference}} on {{Computer Vision Systems}}},
  publisher = {{Springer}},
  author = {Imperoli, Marco and Pretto, Alberto},
  year = {2015},
  pages = {316--328},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\CI9PH6CT\\Imperoli 和 Pretto - 2015 - D $ $^$ $2$ $ $ $ CO Fast and Robust Registration.pdf}
}

@misc{BesucheradresseHomepageEricBrachmann,
  type = {{Document}},
  title = {{Homepage von Eric Brachmann}},
  abstract = {Since November 2017, I'm Research Associate in the Visual Learning Lab, Heidelberg University. This website is not maintained anymore. 
 
NEWS 
 
2017-04-26: The DSAC code (CVPR 17)~is now \ldots},
  language = {de},
  howpublished = {https://tu-dresden.de/ing/informatik/smt/cgv/die-professur/mitarbeiter/eric\_brachmann/?set\_language=de},
  journal = {TU Dresden},
  author = {work Besucheradresse, \textcopyright{} Ludwig Schmutzler Mitarbeiter Name Dipl-Medieninf Eric Brachmann E.-Mail senden Kontaktinformationen Organisationsname Professur f{\"u}r Computergraphik und Visualisierung Professur f{\"u}r Computergraphik und Visualisierung Adresse and {reas-Pfitzmann-Bau}}
}

@article{BrachmannUncertaintyDriven6DPose2016a,
  title = {Uncertainty-{{Driven 6D Pose Estimation}} of {{Objects}} and {{Scenes}} from a {{Single RGB Image}} - {{Supplementary Material}} -},
  language = {en},
  author = {Brachmann, Eric and Michel, Frank and Krull, Alexander and Yang, Michael Ying and Gumhold, Stefan and Rother, Carsten and Dresden, TU},
  month = jun,
  year = {2016},
  pages = {6},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\Y3MP4L4W\\Brachmann 等。 - Uncertainty-Driven 6D Pose Estimation of Objects a.pdf}
}

@article{LiuFastobjectlocalization2012,
  title = {Fast Object Localization and Pose Estimation in Heavy Clutter for Robotic Bin Picking},
  volume = {31},
  number = {8},
  journal = {The International Journal of Robotics Research},
  author = {Liu, Ming-Yu and Tuzel, Oncel and Veeraraghavan, Ashok and Taguchi, Yuichi and Marks, Tim K. and Chellappa, Rama},
  year = {2012},
  pages = {951--973},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\U8PR2TCT\\Liu 等。 - 2012 - Fast object localization and pose estimation in he.pdf}
}

@inproceedings{LiuFastdirectionalchamfer2010,
  title = {Fast Directional Chamfer Matching},
  isbn = {978-1-4244-6984-0},
  doi = {10.1109/CVPR.2010.5539837},
  abstract = {We study the object localization problem in images given a single hand-drawn example or a gallery of shapes as the object model. Although many shape matching algorithms have been proposed for the problem over the decades, chamfer matching remains to be the preferred method when speed and robustness are considered. In this paper, we significantly improve the accuracy of chamfer matching while reducing the computational time from linear to sublinear (shown empirically). Specifically, we incorporate edge orientation information in the matching algorithm such that the resulting cost function is piecewise smooth and the cost variation is tightly bounded. Moreover, we present a sublinear time algorithm for exact computation of the directional chamfer matching score using techniques from 3D distance transforms and directional integral images. In addition, the smooth cost function allows to be bound the cost distribution of large neighborhoods and skip the bad hypotheses within. Experiments show that the proposed approach improves the speed of the original chamfer matching upto an order of 45x, and it is much faster than many state of art techniques while the accuracy is comparable.},
  language = {en},
  publisher = {{IEEE}},
  author = {Liu, Ming-Yu and Tuzel, Oncel and Veeraraghavan, Ashok and Chellappa, Rama},
  month = jun,
  year = {2010},
  pages = {1696-1703},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\33H2NCMJ\\Liu 等。 - 2010 - Fast directional chamfer matching.pdf}
}

@inproceedings{RauterGPUacceleratedfast2012,
  title = {A {{GPU}} Accelerated Fast Directional Chamfer Matching Algorithm and a Detailed Comparison with a Highly Optimized Cpu Implementation},
  booktitle = {Computer {{Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}}), 2012 {{IEEE Computer Society Conference}} On},
  publisher = {{IEEE}},
  author = {Rauter, Michael and Schreiber, David},
  year = {2012},
  pages = {68--75},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\V66YX7VM\\Rauter 和 Schreiber - 2012 - A GPU accelerated fast directional chamfer matchin.pdf}
}

@article{ImperoliActivedetectionlocalization2016,
  title = {Active Detection and Localization of Textureless Objects in Cluttered Environments},
  journal = {arXiv preprint arXiv:1603.07022},
  author = {Imperoli, Marco and Pretto, Alberto},
  year = {2016},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\FDSBUHHZ\\Imperoli 和 Pretto - 2016 - Active detection and localization of textureless o.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\QXDFHI8L\\1603.html}
}

@article{LiuExtremeTrustRegion2018,
  title = {Extreme {{Trust Region Policy Optimization}} for {{Active Object Recognition}}},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  author = {Liu, Huaping and Wu, Yupei and Sun, Fuchun},
  year = {2018}
}

@article{TejaniLatentClassHoughForests2018,
  title = {Latent-{{Class Hough Forests}} for 6 {{DoF Object Pose Estimation}}},
  volume = {40},
  number = {1},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  author = {Tejani, Alykhan and Kouskouridas, Rigas and Doumanoglou, Andreas and Tang, Danhang and Kim, Tae-Kyun},
  year = {2018},
  pages = {119--132}
}

@article{OberkampfIterativeposeestimation1996,
  title = {Iterative Pose Estimation Using Coplanar Feature Points},
  volume = {63},
  number = {3},
  journal = {Computer Vision and Image Understanding},
  author = {Oberkampf, Denis and DeMenthon, Daniel F. and Davis, Larry S.},
  year = {1996},
  pages = {495--511},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\64ZLUK9K\\S1077314296900375.html}
}

@article{ZhangMonocularvisionbasediterative2010,
  title = {Monocular Vision-Based Iterative Pose Estimation Algorithm from Corresponding Feature Points},
  volume = {53},
  number = {8},
  journal = {Science China Information Sciences},
  author = {Zhang, ShiJie and Cao, XiBin and Zhang, Fan and He, Liang},
  year = {2010},
  pages = {1682--1696}
}

@inproceedings{LepetitPointmatchingclassification2004,
  title = {Point Matching as a Classification Problem for Fast and Robust Object Pose Estimation},
  volume = {2},
  booktitle = {Computer {{Vision}} and {{Pattern Recognition}}, 2004. {{CVPR}} 2004. {{Proceedings}} of the 2004 {{IEEE Computer Society Conference}} On},
  publisher = {{IEEE}},
  author = {Lepetit, Vincent and Pilet, Julien and Fua, Pascal},
  year = {2004},
  pages = {II--II},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\UCVH2INU\\Lepetit 等。 - 2004 - Point matching as a classification problem for fas.pdf}
}

@inproceedings{GoldNewalgorithms2D1995,
  title = {New Algorithms for {{2D}} and {{3D}} Point Matching: {{Pose}} Estimation and Correspondence},
  shorttitle = {New Algorithms for {{2D}} and {{3D}} Point Matching},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Gold, Steven and Lu, Chien-Ping and Rangarajan, Anand and Pappu, Suguna and Mjolsness, Eric},
  year = {1995},
  pages = {957--964},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\B5R3F2B4\\Gold 等。 - 1995 - New algorithms for 2D and 3D point matching Pose .pdf;C:\\Users\\ChenCe\\Zotero\\storage\\E2XQN5DL\\Gold 等。 - 1995 - New algorithms for 2D and 3D point matching Pose .pdf}
}

@incollection{LiWorldwideposeestimation2016,
  title = {Worldwide Pose Estimation Using 3d Point Clouds},
  booktitle = {Large-{{Scale Visual Geo}}-{{Localization}}},
  publisher = {{Springer}},
  author = {Li, Yunpeng and Snavely, Noah and Huttenlocher, Daniel P. and Fua, Pascal},
  year = {2016},
  pages = {147--163},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\2Y23RGAN\\Li 等。 - 2016 - Worldwide pose estimation using 3d point clouds.pdf}
}

@inproceedings{Wang3Drelativeposition1992,
  title = {{{3D}} Relative Position and Orientation Estimation Using {{Kalman}} Filter for Robot Control},
  booktitle = {Robotics and {{Automation}}, 1992. {{Proceedings}}., 1992 {{IEEE International Conference}} On},
  publisher = {{IEEE}},
  author = {Wang, Jiang and Wilson, William J.},
  year = {1992},
  pages = {2638--2645},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\SE5QQZCK\\220044.html}
}

@article{DementhonModelbasedobjectpose1995,
  title = {Model-Based Object Pose in 25 Lines of Code},
  volume = {15},
  number = {1-2},
  journal = {International journal of computer vision},
  author = {Dementhon, Daniel F. and Davis, Larry S.},
  year = {1995},
  pages = {123--141},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\4D45D9JA\\BF01450852.html}
}

@article{QuanLinearnpointcamera1999,
  title = {Linear N-Point Camera Pose Determination},
  volume = {21},
  number = {8},
  journal = {IEEE Transactions on pattern analysis and machine intelligence},
  author = {Quan, Long and Lan, Zhongdan},
  year = {1999},
  pages = {774--780},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\9L6EX59V\\Quan 和 Lan - 1999 - Linear n-point camera pose determination.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\U2FPGFMU\\784291.html}
}

@article{LepetitEpnpaccuratesolution2009,
  title = {Epnp: {{An}} Accurate o (n) Solution to the Pnp Problem},
  volume = {81},
  shorttitle = {Epnp},
  number = {2},
  journal = {International journal of computer vision},
  author = {Lepetit, Vincent and {Moreno-Noguer}, Francesc and Fua, Pascal},
  year = {2009},
  pages = {155},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\E6FPCLAK\\Lepetit 等。 - 2009 - Epnp An accurate o (n) solution to the pnp proble.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\T63RMWA7\\s11263-008-0152-6.html}
}

@inproceedings{RamalingamPoseestimationusing2011,
  title = {Pose Estimation Using Both Points and Lines for Geo-Localization},
  booktitle = {Robotics and {{Automation}} ({{ICRA}}), 2011 {{IEEE International Conference}} On},
  publisher = {{IEEE}},
  author = {Ramalingam, Srikumar and Bouaziz, Sofien and Sturm, Peter},
  year = {2011},
  pages = {4716--4723},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\I2FGBVE9\\Ramalingam 等。 - 2011 - Pose estimation using both points and lines for ge.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\88JVE95F\\5979781.html}
}

@article{Lirobustsolutionperspectivenpoint2012,
  title = {A Robust {{O}} (n) Solution to the Perspective-n-Point Problem},
  volume = {34},
  number = {7},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  author = {Li, Shiqi and Xu, Chi and Xie, Ming},
  year = {2012},
  pages = {1444--1450},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\8HDDI3TM\\Li 等。 - 2012 - A robust O (n) solution to the perspective-n-point.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\DP2SIS4I\\6143946.html}
}

@article{Nisterefficientsolutionfivepoint2004,
  title = {An Efficient Solution to the Five-Point Relative Pose Problem},
  volume = {26},
  number = {6},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  author = {Nist{\'e}r, David},
  year = {2004},
  pages = {756--770},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\EN2XBDZ3\\Nistér - 2004 - An efficient solution to the five-point relative p.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\G2AGUS2Q\\1288525.html}
}

@inproceedings{WongRobustefficientpose2017,
  title = {Robust and Efficient Pose Tracking Using Perspective-Four-Point Algorithm and {{Kalman}} Filter},
  booktitle = {Mechanical, {{System}} and {{Control Engineering}} ({{ICMSC}}), 2017 {{International Conference}} On},
  publisher = {{IEEE}},
  author = {Wong, Kin Hong and Yu, Ying Kin and Fung, Ho Yin and Kam, Ho Chuen and Tsui, Kwun Pang},
  year = {2017},
  pages = {240--244},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\4Q6TIKCK\\Wong 等。 - 2017 - Robust and efficient pose tracking using perspecti.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\53749SAA\\7959479.html}
}

@article{DhomeDeterminationattitude3D1989,
  title = {Determination of the Attitude of {{3D}} Objects from a Single Perspective View},
  volume = {11},
  number = {12},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  author = {Dhome, Michel and Richetin, Marc and Lapreste, J.-T. and Rives, Gerard},
  year = {1989},
  pages = {1265--1278},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\VBMMBARW\\41365.html}
}

@article{FischerParadigmModelFitting1981,
  title = {A {{Paradigm}} for {{Model Fitting}} with {{Applications}} to {{Image Analysis}} and {{Automated Cartography}}},
  volume = {24},
  number = {6},
  journal = {Comm. ACM},
  author = {Fischer, M. A.},
  year = {1981},
  pages = {381--395}
}

@article{GaoCompletesolutionclassification2003,
  title = {Complete Solution Classification for the Perspective-Three-Point Problem},
  volume = {25},
  number = {8},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  author = {Gao, Xiao-Shan and Hou, Xiao-Rong and Tang, Jianliang and Cheng, Hang-Fei},
  year = {2003},
  pages = {930--943},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\XGIJKGM5\\Gao 等。 - 2003 - Complete solution classification for the perspecti.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\JI473UK7\\1217599.html}
}

@inproceedings{BaumbergReliablefeaturematching2000,
  title = {Reliable Feature Matching across Widely Separated Views},
  volume = {1},
  booktitle = {Computer {{Vision}} and {{Pattern Recognition}}, 2000. {{Proceedings}}. {{IEEE Conference}} On},
  publisher = {{IEEE}},
  author = {Baumberg, Adam},
  year = {2000},
  pages = {774--781},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\SCE52F8K\\Baumberg - 2000 - Reliable feature matching across widely separated .pdf;C:\\Users\\ChenCe\\Zotero\\storage\\L2WSH2X9\\855899.html}
}

@inproceedings{Mikolajczykaffineinvariantinterest2002,
  title = {An Affine Invariant Interest Point Detector},
  booktitle = {European Conference on Computer Vision},
  publisher = {{Springer}},
  author = {Mikolajczyk, Krystian and Schmid, Cordelia},
  year = {2002},
  pages = {128--142},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\HL9XDWI2\\Mikolajczyk 和 Schmid - 2002 - An affine invariant interest point detector.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\XXPMTCRW\\10.html}
}

@inproceedings{LoweObjectrecognitionlocal1999,
  title = {Object Recognition from Local Scale-Invariant Features},
  volume = {2},
  booktitle = {Computer Vision, 1999. {{The}} Proceedings of the Seventh {{IEEE}} International Conference On},
  publisher = {{Ieee}},
  author = {Lowe, David G.},
  year = {1999},
  pages = {1150--1157},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\BT37UUR9\\Lowe - 1999 - Object recognition from local scale-invariant feat.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\7MS2HGLE\\790410.html}
}

@inproceedings{NayarRealtime100object1996,
  title = {Real-Time 100 Object Recognition System},
  volume = {3},
  booktitle = {Robotics and {{Automation}}, 1996. {{Proceedings}}., 1996 {{IEEE International Conference}} On},
  publisher = {{IEEE}},
  author = {Nayar, Shree K. and Nene, Sameer A. and Murase, Hiroshi},
  year = {1996},
  pages = {2321--2325},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\9V8RDUL6\\Nayar 等。 - 1996 - Real-time 100 object recognition system.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\RQWY3ZIQ\\506510.html}
}

@inproceedings{AllezardRecognition3dtextured2000,
  title = {Recognition of 3d Textured Objects by Mixing View-Based and Model-Based Representations},
  volume = {1},
  booktitle = {Pattern {{Recognition}}, 2000. {{Proceedings}}. 15th {{International Conference}} On},
  publisher = {{IEEE}},
  author = {Allezard, Nicolas and Dhome, Michel and Jurie, Fr{\'e}d{\'e}ric},
  year = {2000},
  pages = {960--963},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\57ZHGK4X\\Allezard 等。 - 2000 - Recognition of 3d textured objects by mixing view-.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\XDK8B86J\\905614.html}
}

@inproceedings{ViolaRapidobjectdetection2001,
  title = {Rapid Object Detection Using a Boosted Cascade of Simple Features},
  volume = {1},
  booktitle = {Computer {{Vision}} and {{Pattern Recognition}}, 2001. {{CVPR}} 2001. {{Proceedings}} of the 2001 {{IEEE Computer Society Conference}} On},
  publisher = {{IEEE}},
  author = {Viola, Paul and Jones, Michael},
  year = {2001},
  pages = {I--I},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\WKZGMIZ7\\Viola 和 Jones - 2001 - Rapid object detection using a boosted cascade of .pdf;C:\\Users\\ChenCe\\Zotero\\storage\\UQWBJM7N\\990517.html}
}

@inproceedings{Harriscombinedcorneredge1988,
  title = {A Combined Corner and Edge Detector.},
  volume = {15},
  booktitle = {Alvey Vision Conference},
  publisher = {{Citeseer}},
  author = {Harris, Chris and Stephens, Mike},
  year = {1988},
  pages = {10--5244}
}

@article{AnsarLinearposeestimation2003,
  title = {Linear Pose Estimation from Points or Lines},
  volume = {25},
  number = {5},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author = {Ansar, Adnan and Daniilidis, Konstantinos},
  year = {2003},
  pages = {578--589},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\8NYF5FME\\Ansar 和 Daniilidis - 2003 - Linear pose estimation from points or lines.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\NBMBBZUG\\1195992.html}
}

@article{LuFastgloballyconvergent2000,
  title = {Fast and Globally Convergent Pose Estimation from Video Images},
  volume = {22},
  number = {6},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author = {Lu, C.-P. and Hager, Gregory D. and Mjolsness, Eric},
  year = {2000},
  pages = {610--622},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\S6Z4K82Z\\Lu 等。 - 2000 - Fast and globally convergent pose estimation from .pdf;C:\\Users\\ChenCe\\Zotero\\storage\\KIITZ94S\\862199.html}
}

@inproceedings{SkrypnykScenemodellingrecognition2004,
  title = {Scene Modelling, Recognition and Tracking with Invariant Image Features},
  booktitle = {Mixed and {{Augmented Reality}}, 2004. {{ISMAR}} 2004. {{Third IEEE}} and {{ACM International Symposium}} On},
  publisher = {{IEEE}},
  author = {Skrypnyk, Iryna and Lowe, David G.},
  year = {2004},
  pages = {110--119},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\6Z7VNMH6\\Skrypnyk 和 Lowe - 2004 - Scene modelling, recognition and tracking with inv.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\Q5B9EPHH\\1383048.html}
}

@article{CrivellaroRobust3dobject2017,
  title = {Robust 3d Object Tracking from Monocular Images Using Stable Parts},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  author = {Crivellaro, Alberto and Rad, Mahdi and Verdie, Yannick and Yi, Kwang Moo and Fua, Pascal and Lepetit, Vincent},
  year = {2017},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\U5FDXPSV\\Crivellaro 等。 - 2017 - Robust 3d object tracking from monocular images us.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\GNJ685YB\\7934426.html}
}

@article{RadFeatureMappingLearning2017,
  title = {Feature {{Mapping}} for {{Learning Fast}} and {{Accurate 3D Pose Inference}} from {{Synthetic Images}}},
  journal = {arXiv preprint arXiv:1712.03904},
  author = {Rad, Mahdi and Oberweger, Markus and Lepetit, Vincent},
  year = {2017},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\K78JLWB7\\Rad 等。 - 2017 - Feature Mapping for Learning Fast and Accurate 3D .pdf;C:\\Users\\ChenCe\\Zotero\\storage\\LXHGQPZZ\\1712.html}
}

@inproceedings{KneipUpnpoptimalsolution2014,
  title = {Upnp: {{An}} Optimal o (n) Solution to the Absolute Pose Problem with Universal Applicability},
  shorttitle = {Upnp},
  booktitle = {European {{Conference}} on {{Computer Vision}}},
  publisher = {{Springer}},
  author = {Kneip, Laurent and Li, Hongdong and Seo, Yongduek},
  year = {2014},
  pages = {127--142},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\INENXCE7\\Kneip 等。 - 2014 - Upnp An optimal o (n) solution to the absolute po.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\AVXQ4YS9\\978-3-319-10590-1_9.html}
}

@article{HadfieldHARDPnPPnPOptimization2018,
  title = {{{HARD}}-{{PnP}}: {{PnP Optimization Using}} a {{Hybrid Approximate Representation}}},
  shorttitle = {{{HARD}}-{{PnP}}},
  journal = {IEEE transactions on Pattern Analysis and Machine Intelligence},
  author = {Hadfield, Simon and Lebeda, Karel and Bowden, Richard},
  year = {2018},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\8AI54SCU\\Hadfield 等。 - 2018 - HARD-PnP PnP Optimization Using a Hybrid Approxim.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\LDXPMSPM\\845787.html}
}

@inproceedings{WohlhartLearningdescriptorsobject2015,
  title = {Learning Descriptors for Object Recognition and 3d Pose Estimation},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Wohlhart, Paul and Lepetit, Vincent},
  year = {2015},
  pages = {3109--3118},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\BVWJ5SJ8\\Wohlhart 和 Lepetit - 2015 - Learning descriptors for object recognition and 3d.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\J9JSMJIG\\Wohlhart 和 Lepetit - 2015 - Learning descriptors for object recognition and 3d.pdf}
}

@article{Rozantsevsharingweightsdeep2018,
  title = {Beyond Sharing Weights for Deep Domain Adaptation},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author = {Rozantsev, Artem and Salzmann, Mathieu and Fua, Pascal},
  year = {2018},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\75JSDHQJ\\Rozantsev 等。 - 2018 - Beyond sharing weights for deep domain adaptation.pdf}
}

@inproceedings{GirshickRichfeaturehierarchies2014,
  title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
  booktitle = {Proceedings of the {{IEEE}} Conference on Computer Vision and Pattern Recognition},
  author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  year = {2014},
  pages = {580--587},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\4F7VX2VC\\Girshick 等。 - 2014 - Rich feature hierarchies for accurate object detec.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\KRYMWGRQ\\Girshick 等。 - 2014 - Rich feature hierarchies for accurate object detec.pdf}
}

@inproceedings{HuDeeptransfermetric2015,
  title = {Deep Transfer Metric Learning},
  booktitle = {Computer {{Vision}} and {{Pattern Recognition}} ({{CVPR}}), 2015 {{IEEE Conference}} On},
  publisher = {{IEEE}},
  author = {Hu, Junlin and Lu, Jiwen and Tan, Yap-Peng},
  year = {2015},
  pages = {325--333},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\6JTEVIB9\\Hu 等。 - 2015 - Deep transfer metric learning.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\9MRCZD7H\\Hu 等。 - 2015 - Deep transfer metric learning.pdf}
}

@article{GaninUnsuperviseddomainadaptation2014,
  title = {Unsupervised Domain Adaptation by Backpropagation},
  journal = {arXiv preprint arXiv:1409.7495},
  author = {Ganin, Yaroslav and Lempitsky, Victor},
  year = {2014},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\924QZI42\\Ganin 和 Lempitsky - 2014 - Unsupervised domain adaptation by backpropagation.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\25VU8I8J\\1409.html}
}

@article{HinterstoisserPreTrainedImageFeatures2017,
  title = {On {{Pre}}-{{Trained Image Features}} and {{Synthetic Images}} for {{Deep Learning}}},
  journal = {arXiv preprint arXiv:1710.10710},
  author = {Hinterstoisser, Stefan and Lepetit, Vincent and Wohlhart, Paul and Konolige, Kurt},
  year = {2017},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\ZILJJXQQ\\Hinterstoisser 等。 - 2017 - On Pre-Trained Image Features and Synthetic Images.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\425UTFRN\\1710.html}
}

@inproceedings{KehlSSD6DMakingRGBbased2017,
  title = {{{SSD}}-{{6D}}: {{Making RGB}}-Based {{3D}} Detection and {{6D}} Pose Estimation Great Again},
  shorttitle = {{{SSD}}-{{6D}}},
  booktitle = {{{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Kehl, Wadim and Manhardt, Fabian and Tombari, Federico and Ilic, Slobodan and Navab, Nassir},
  year = {2017},
  pages = {1521--1529},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\GJGC7FEX\\Kehl 等。 - 2017 - SSD-6D Making RGB-based 3D detection and 6D pose .pdf;C:\\Users\\ChenCe\\Zotero\\storage\\SBG29637\\Kehl 等。 - 2017 - SSD-6D Making RGB-based 3D detection and 6D pose .pdf}
}

@article{GirshickRegionbasedconvolutionalnetworks2016,
  title = {Region-Based Convolutional Networks for Accurate Object Detection and Segmentation},
  volume = {38},
  number = {1},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  year = {2016},
  pages = {142--158},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\S8GI6QAT\\7112511.html}
}

@inproceedings{RenFasterrcnnrealtime2015,
  title = {Faster R-Cnn: {{Towards}} Real-Time Object Detection with Region Proposal Networks},
  shorttitle = {Faster R-Cnn},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  year = {2015},
  pages = {91--99},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\AJJXXKBY\\Ren 等。 - 2015 - Faster r-cnn Towards real-time object detection w.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\HA7BMVQZ\\5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.html}
}

@inproceedings{Mousavian3dboundingbox2017,
  title = {3d Bounding Box Estimation Using Deep Learning and Geometry},
  booktitle = {Computer {{Vision}} and {{Pattern Recognition}} ({{CVPR}}), 2017 {{IEEE Conference}} On},
  publisher = {{IEEE}},
  author = {Mousavian, Arsalan and Anguelov, Dragomir and Flynn, John and Ko{\v s}eck{\'a}, Jana},
  year = {2017},
  pages = {5632--5640},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\6SDISJWB\\Mousavian 等。 - 2017 - 3d bounding box estimation using deep learning and.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\MS4XAL7W\\Mousavian 等。 - 2017 - 3d bounding box estimation using deep learning and.pdf}
}

@inproceedings{PoirsonFastsingleshot2016,
  title = {Fast Single Shot Detection and Pose Estimation},
  booktitle = {{{3D Vision}} ({{3DV}}), 2016 {{Fourth International Conference}} On},
  publisher = {{IEEE}},
  author = {Poirson, Patrick and Ammirato, Phil and Fu, Cheng-Yang and Liu, Wei and Kosecka, Jana and Berg, Alexander C.},
  year = {2016},
  pages = {676--684},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\X8MBRXD7\\Poirson 等。 - 2016 - Fast single shot detection and pose estimation.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\6K5ZNB84\\7785144.html}
}

@article{Doumanoglou6Dobjectdetection2015,
  title = {{{6D}} Object Detection and Next-Best-View Prediction in the Crowd},
  journal = {arXiv preprint},
  author = {Doumanoglou, Andreas and Kouskouridas, Rigas and Malassiotis, Sotiris and Kim, Tae-Kyun},
  year = {2015},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\DT2QCGBL\\Doumanoglou 等。 - 2015 - 6D object detection and next-best-view prediction .pdf;C:\\Users\\ChenCe\\Zotero\\storage\\L492UZEB\\Doumanoglou 等。 - 2015 - 6D object detection and next-best-view prediction .pdf}
}

@inproceedings{HodanDetectionfine3D2015,
  title = {Detection and Fine {{3D}} Pose Estimation of Texture-Less Objects in {{RGB}}-{{D}} Images},
  booktitle = {Intelligent {{Robots}} and {{Systems}} ({{IROS}}), 2015 {{IEEE}}/{{RSJ International Conference}} On},
  publisher = {{IEEE}},
  author = {Hoda{\v n}, Tom{\'a}{\v s} and Zabulis, Xenophon and Lourakis, Manolis and Obdr{\v z}{\'a}lek, {\v S}t{\v e}p{\'a}n and Matas, Ji{\v r}{\'\i}},
  year = {2015},
  pages = {4421--4428},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\GD6LRXRD\\7354005.html}
}

@inproceedings{KehlDeeplearninglocal2016a,
  title = {Deep Learning of Local {{RGB}}-{{D}} Patches for {{3D}} Object Detection and {{6D}} Pose Estimation},
  booktitle = {European {{Conference}} on {{Computer Vision}}},
  publisher = {{Springer}},
  author = {Kehl, Wadim and Milletari, Fausto and Tombari, Federico and Ilic, Slobodan and Navab, Nassir},
  year = {2016},
  pages = {205--220},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\EAHBC5IK\\Kehl 等。 - 2016 - Deep learning of local RGB-D patches for 3D object.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\EH9EXY4E\\978-3-319-46487-9_13.html}
}

@inproceedings{TejaniLatentclasshoughforests2014,
  title = {Latent-Class Hough Forests for {{3D}} Object Detection and Pose Estimation},
  booktitle = {European {{Conference}} on {{Computer Vision}}},
  publisher = {{Springer}},
  author = {Tejani, Alykhan and Tang, Danhang and Kouskouridas, Rigas and Kim, Tae-Kyun},
  year = {2014},
  pages = {462--477},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\T8KCSWTJ\\Tejani 等。 - 2014 - Latent-class hough forests for 3D object detection.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\UC96R7RD\\978-3-319-10599-4_30.html}
}

@article{DingPoseinvariantfacerecognition2017,
  title = {Pose-Invariant Face Recognition with Homography-Based Normalization},
  volume = {66},
  journal = {Pattern Recognition},
  author = {Ding, Changxing and Tao, Dacheng},
  year = {2017},
  pages = {144--152},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\7ERLGITA\\S0031320316303831.html}
}

@article{GaoSemisupervisedsparserepresentation2017,
  title = {Semi-Supervised Sparse Representation Based Classification for Face Recognition with Insufficient Labeled Samples},
  volume = {26},
  number = {5},
  journal = {IEEE Transactions on Image Processing},
  author = {Gao, Yuan and Ma, Jiayi and Yuille, Alan L.},
  year = {2017},
  pages = {2545--2560},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\CLHVZH2B\\Gao 等。 - 2017 - Semi-supervised sparse representation based classi.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\PKPFSC9R\\7865903.html}
}

@article{TangVehicledetectionrecognition2017,
  title = {Vehicle Detection and Recognition for Intelligent Traffic Surveillance System},
  volume = {76},
  number = {4},
  journal = {Multimedia tools and applications},
  author = {Tang, Yong and Zhang, Congzhe and Gu, Renshu and Li, Peng and Yang, Bin},
  year = {2017},
  pages = {5817--5832},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\QGKT84KB\\Tang 等。 - 2017 - Vehicle detection and recognition for intelligent .pdf;C:\\Users\\ChenCe\\Zotero\\storage\\QE55Y2X7\\s11042-015-2520-x.html}
}

@inproceedings{LinInfraredvehiclerecognition2018,
  title = {Infrared Vehicle Recognition Using Unsupervised Feature Learning Based on {{K}}-Feature},
  volume = {10608},
  booktitle = {Society of {{Photo}}-{{Optical Instrumentation Engineers}} ({{SPIE}}) {{Conference Series}}},
  author = {Lin, Jin and Tan, Yihua and Xia, Haijiao and Tian, Jinwen},
  year = {2018},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\N5XB8HBL\\2018SPIE10608E..html}
}

@article{FieraruLearningRefineHuman2018,
  title = {Learning to {{Refine Human Pose Estimation}}},
  journal = {arXiv preprint arXiv:1804.07909},
  author = {Fieraru, Mihai and Khoreva, Anna and Pishchulin, Leonid and Schiele, Bernt},
  year = {2018},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\9LB9ZQF7\\Fieraru 等。 - 2018 - Learning to Refine Human Pose Estimation.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\BD8PIAQA\\1804.html}
}

@inproceedings{Chen3dhumanpose2017,
  title = {3d Human Pose Estimation= 2d Pose Estimation+ Matching},
  volume = {2},
  booktitle = {{{CVPR}}},
  author = {Chen, Ching-Hang and Ramanan, Deva},
  year = {2017},
  pages = {6},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\ER4XFWYE\\Chen 和 Ramanan - 2017 - 3d human pose estimation= 2d pose estimation+ matc.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\YVTGJN43\\Chen 和 Ramanan - 2017 - 3d human pose estimation= 2d pose estimation+ matc.pdf}
}

@inproceedings{HeSpatialpyramidpooling2014,
  title = {Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition},
  booktitle = {European Conference on Computer Vision},
  publisher = {{Springer}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2014},
  pages = {346--361},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\F7KRSUKL\\He 等。 - 2014 - Spatial pyramid pooling in deep convolutional netw.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\EJ8QXCP9\\978-3-319-10578-9_23.html}
}

@inproceedings{RedmonYouonlylook2016,
  title = {You Only Look Once: {{Unified}}, Real-Time Object Detection},
  shorttitle = {You Only Look Once},
  booktitle = {Proceedings of the {{IEEE}} Conference on Computer Vision and Pattern Recognition},
  author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  year = {2016},
  pages = {779--788},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\2W63HQCW\\Redmon 等。 - 2016 - You only look once Unified, real-time object dete.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\CRUA4A54\\Redmon 等。 - 2016 - You only look once Unified, real-time object dete.pdf}
}

@article{ParkFastautomaticobject2010,
  title = {Fast and Automatic Object Pose Estimation for Range Images on the {{GPU}}},
  volume = {21},
  number = {5},
  journal = {Machine Vision and Applications},
  author = {Park, In Kyu and Germann, Marcel and Breitenstein, Michael D. and Pfister, Hanspeter},
  year = {2010},
  pages = {749--766},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\8YUK3F5M\\Park 等。 - 2010 - Fast and automatic object pose estimation for rang.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\2KGDG4SJ\\s00138-009-0209-8.html}
}

@inproceedings{HinterstoisserModelbasedtraining2012,
  title = {Model Based Training, Detection and Pose Estimation of Texture-Less 3d Objects in Heavily Cluttered Scenes},
  booktitle = {Asian Conference on Computer Vision},
  publisher = {{Springer}},
  author = {Hinterstoisser, Stefan and Lepetit, Vincent and Ilic, Slobodan and Holzer, Stefan and Bradski, Gary and Konolige, Kurt and Navab, Nassir},
  year = {2012},
  pages = {548--562},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\DB4A9SS6\\978-3-642-37331-2_42.html}
}

@inproceedings{LeCunHandwrittendigitrecognition1990,
  title = {Handwritten Digit Recognition with a Back-Propagation Network},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {LeCun, Yann and Boser, Bernhard E. and Denker, John S. and Henderson, Donnie and Howard, Richard E. and Hubbard, Wayne E. and Jackel, Lawrence D.},
  year = {1990},
  pages = {396--404},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\PU427DI7\\LeCun 等。 - 1990 - Handwritten digit recognition with a back-propagat.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\ZIA82UHJ\\LeCun 等。 - 1990 - Handwritten digit recognition with a back-propagat.pdf}
}

@article{RussakovskyImagenetlargescale2015,
  title = {Imagenet Large Scale Visual Recognition Challenge},
  volume = {115},
  number = {3},
  journal = {International Journal of Computer Vision},
  author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael},
  year = {2015},
  pages = {211--252},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\DM2AIE7J\\Russakovsky 等。 - 2015 - Imagenet large scale visual recognition challenge.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\2JR2U24G\\s11263-015-0816-y.html}
}

@inproceedings{ValentinExploitinguncertaintyregression2015,
  title = {Exploiting Uncertainty in Regression Forests for Accurate Camera Relocalization},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Valentin, Julien and {Nie$\backslash$s sner}, Matthias and Shotton, Jamie and Fitzgibbon, Andrew and Izadi, Shahram and Torr, Philip HS},
  year = {2015},
  pages = {4400--4408},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\ET28EH29\\Valentin 等。 - 2015 - Exploiting uncertainty in regression forests for a.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\ZSSSVSUK\\Valentin 等。 - 2015 - Exploiting uncertainty in regression forests for a.pdf}
}

@article{RanXuNiXianShiJiZengQiangXianShiJiZhuZaiGongYeSheJiZhongDeYingYong2010,
  title = {{虚拟现实及增强现实技术在工业设计中的应用}},
  issn = {0253-2743},
  lccn = {50-1085/TN},
  abstract = {工业设计技术已日益成为产品创新、价值增值过程中重要的手段。由于现有技术支撑手段的局限,传统工业设计过程中反复叠代修改的"设计-快速原形(CAD$>$RP)"循环制约了设计师发挥的空间。虚拟现实及增强现实技术的应用可以为设计师提供一个自然、辜观、交互的环境表达设计思想。虽然已有大量的文献描述混合现实技术的进展及其在制造业的应用,但还鲜有专门着重于工业设计这一重要的领域。本文从一个工业设计工程师的角度阐述了混合现实技术在工业设计中的应用,尤其着重于在增强现实环境下的三维空间设计、数字样机和虚拟装配,并与现有的设计方式进行了比较。},
  language = {中文;},
  number = {01},
  journal = {激光杂志},
  author = {冉, 洋 and 朱, 飞 and 陈, 康},
  year = {2010},
  keywords = {工业设计,数字样机,虚拟空间设计,虚拟现实,虚拟装配,增强现实,assembly.,augmented reality,hybrid prototyping,industrial design,spatial design,virtual reality},
  pages = {4-6}
}

@inproceedings{VikstenComparisonlocalimage2009,
  title = {Comparison of Local Image Descriptors for Full 6 Degree-of-Freedom Pose Estimation},
  booktitle = {Robotics and {{Automation}}, 2009. {{ICRA}}'09. {{IEEE International Conference}} On},
  publisher = {{IEEE}},
  author = {Viksten, Fredrik and Forss{\'e}n, Per-Erik and Johansson, Bjorn and Moe, Anders},
  year = {2009},
  pages = {2779--2786},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\GQBHUIPE\\Viksten 等。 - 2009 - Comparison of local image descriptors for full 6 d.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\RUI6HSCG\\5152360.html}
}

@article{DoumanoglouRecovering6DObject2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.07506},
  primaryClass = {cs},
  title = {Recovering {{6D Object Pose}} and {{Predicting Next}}-{{Best}}-{{View}} in the {{Crowd}}},
  abstract = {Object detection and 6D pose estimation in the crowd (scenes with multiple object instances, severe foreground occlusions and background distractors), has become an important problem in many rapidly evolving technological areas such as robotics and augmented reality. Single shot-based 6D pose estimators with manually designed features are still unable to tackle the above challenges, motivating the research towards unsupervised feature learning and next-best-view estimation. In this work, we present a complete framework for both single shot-based 6D object pose estimation and next-best-view prediction based on Hough Forests, the state of the art object pose estimator that performs classification and regression jointly. Rather than using manually designed features we a) propose an unsupervised feature learnt from depth-invariant patches using a Sparse Autoencoder and b) offer an extensive evaluation of various state of the art features. Furthermore, taking advantage of the clustering performed in the leaf nodes of Hough Forests, we learn to estimate the reduction of uncertainty in other views, formulating the problem of selecting the next-best-view. To further improve pose estimation, we propose an improved joint registration and hypotheses verification module as a final refinement step to reject false detections. We provide two additional challenging datasets inspired from realistic scenarios to extensively evaluate the state of the art and our framework. One is related to domestic environments and the other depicts a bin-picking scenario mostly found in industrial settings. We show that our framework significantly outperforms state of the art both on public and on our datasets.},
  journal = {arXiv:1512.07506 [cs]},
  author = {Doumanoglou, Andreas and Kouskouridas, Rigas and Malassiotis, Sotiris and Kim, Tae-Kyun},
  month = dec,
  year = {2015},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\MNE98H9C\\Doumanoglou 等。 - 2015 - Recovering 6D Object Pose and Predicting Next-Best.pdf}
}

@article{HinterstoisserGradientresponsemaps2012,
  title = {Gradient Response Maps for Real-Time Detection of Textureless Objects},
  volume = {34},
  number = {5},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author = {Hinterstoisser, Stefan and Cagniart, Cedric and Ilic, Slobodan and Sturm, Peter and Navab, Nassir and Fua, Pascal and Lepetit, Vincent},
  year = {2012},
  pages = {876--888},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\NAQACMXD\\Hinterstoisser 等。 - 2012 - Gradient response maps for real-time detection of .pdf}
}

@article{Ahmedimprovedperturbobserve2015,
  title = {An Improved Perturb and Observe ({{P}}\&{{O}}) Maximum Power Point Tracking ({{MPPT}}) Algorithm for Higher Efficiency},
  volume = {150},
  journal = {Applied Energy},
  author = {Ahmed, Jubaer and Salam, Zainal},
  year = {2015},
  pages = {97--108},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\GRKBK4H3\\S0306261915004456.html}
}

@inproceedings{XiangObjectnet3dlargescale2016,
  title = {Objectnet3d: {{A}} Large Scale Database for 3d Object Recognition},
  shorttitle = {Objectnet3d},
  booktitle = {European {{Conference}} on {{Computer Vision}}},
  publisher = {{Springer}},
  author = {Xiang, Yu and Kim, Wonhui and Chen, Wei and Ji, Jingwei and Choy, Christopher and Su, Hao and Mottaghi, Roozbeh and Guibas, Leonidas and Savarese, Silvio},
  year = {2016},
  pages = {160--176},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\CBQ7V6VF\\Xiang 等。 - 2016 - Objectnet3d A large scale database for 3d object .pdf}
}

@techreport{ZhongGuoXinXiTongXinYanJiuYuanXuNiZengQiangXianShiBaiPiShu2017,
  title = {虚拟（增强）现实白皮书},
  author = {中国信息通信研究院},
  month = sep,
  year = {2017}
}

@patent{MedasaniMethodobjectlocalization2018,
  title = {Method for Object Localization and Pose Estimation for an Object of Interest},
  author = {Medasani, Swarup and Meltzer, Jason and Xu, Jiejun and Chen, Zhichao and Sundareswara, Rashmi N. and Payton, David W. and Uhlenbrock, Ryan M. and Barajas, Leandro G. and Kim, Kyungnam},
  month = jan,
  year = {2018},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\IA2EXMAI\\en.html}
}

@misc{GalleryMatplotlibdocumentation,
  title = {Gallery \textemdash{} {{Matplotlib}} 2.2.2 Documentation},
  howpublished = {https://matplotlib.org/gallery/index.html\#miscellaneous}
}

@inproceedings{WangPoseoptimizationedge2017,
  title = {Pose Optimization in Edge Distance Field for Textureless {{3D}} Object Tracking},
  booktitle = {Proceedings of the {{Computer Graphics International Conference}}},
  publisher = {{ACM}},
  author = {Wang, Bin and Zhong, Fan and Qin, Xueying},
  year = {2017},
  pages = {32},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\LNFP262W\\Wang 等。 - 2017 - Pose optimization in edge distance field for textu.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\9JGIZYCQ\\citation.html}
}

@article{WangGlobaloptimalsearching2015,
  title = {Global Optimal Searching for Textureless {{3D}} Object Tracking},
  volume = {31},
  number = {6-8},
  journal = {The Visual Computer},
  author = {Wang, Guofeng and Wang, Bin and Zhong, Fan and Qin, Xueying and Chen, Baoquan},
  year = {2015},
  pages = {979--988}
}

@inproceedings{ParkMultiple3dobject2008,
  title = {Multiple 3d Object Tracking for Augmented Reality},
  booktitle = {Proceedings of the 7th {{IEEE}}/{{ACM International Symposium}} on {{Mixed}} and {{Augmented Reality}}},
  publisher = {{IEEE Computer Society}},
  author = {Park, Youngmin and Lepetit, Vincent and Woo, Woontack},
  year = {2008},
  pages = {117--120},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\XWLFDUZ6\\Park 等。 - 2008 - Multiple 3d object tracking for augmented reality.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\SZPXEWTY\\citation.html}
}

@article{VacchettiStablerealtime3d2004,
  title = {Stable Real-Time 3d Tracking Using Online and Offline Information},
  volume = {26},
  number = {10},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  author = {Vacchetti, Luca and Lepetit, Vincent and Fua, Pascal},
  year = {2004},
  pages = {1385--1391},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\XPU24I8M\\Vacchetti 等。 - 2004 - Stable real-time 3d tracking using online and offl.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\RM95S9CQ\\1323807.html}
}

@inproceedings{HarrisRAPIDavideorate1990,
  title = {{{RAPID}}-a Video Rate Object Tracker.},
  booktitle = {{{BMVC}}},
  author = {Harris, Chris and Stennett, Carl},
  year = {1990},
  pages = {1--6},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\WGZE3XFM\\Harris 和 Stennett - 1990 - RAPID-a video rate object tracker..pdf;C:\\Users\\ChenCe\\Zotero\\storage\\YIPA4VAS\\Harris 和 Stennett - 1990 - RAPID-a video rate object tracker..pdf}
}

@article{Marchand2D3Dmodelbased2001,
  title = {A {{2D}}\textendash{{3D}} Model-Based Approach to Real-Time Visual Tracking},
  volume = {19},
  number = {13},
  journal = {Image and Vision Computing},
  author = {Marchand, Eric and Bouthemy, Patrick and Chaumette, Fran{\c c}ois},
  year = {2001},
  pages = {941--955},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\REZGEBKW\\Marchand 等。 - 2001 - A 2D–3D model-based approach to real-time visual t.pdf}
}

@inproceedings{Comportrealtimetrackermarkerless2003,
  title = {A Real-Time Tracker for Markerless Augmented Reality},
  booktitle = {Proceedings of the 2nd {{IEEE}}/{{ACM International Symposium}} on {{Mixed}} and {{Augmented Reality}}},
  publisher = {{IEEE Computer Society}},
  author = {Comport, Andrew I. and Marchand, {\'E}ric and Chaumette, Fran{\c c}ois},
  year = {2003},
  pages = {36},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\V2S2GCET\\Comport 等。 - 2003 - A real-time tracker for markerless augmented reali.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\AQV5TKQV\\citation.html}
}

@inproceedings{WuestAdaptivelinetracking2005,
  title = {Adaptive Line Tracking with Multiple Hypotheses for Augmented Reality},
  booktitle = {Proceedings of the 4th {{IEEE}}/{{ACM International Symposium}} on {{Mixed}} and {{Augmented Reality}}},
  publisher = {{IEEE Computer Society}},
  author = {Wuest, Harald and Vial, Florent and Stricker, Didier},
  year = {2005},
  pages = {62--69},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\82ZHA97A\\Wuest 等。 - 2005 - Adaptive line tracking with multiple hypotheses fo.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\FUKKQ67G\\citation.html}
}

@article{ChenHunHeXianShiZhongDeXuShiRongHeYuRenJiZhiNengJiaoRong2016,
  title = {{混合现实中的虚实融合与人机智能交融}},
  issn = {1674-7267},
  lccn = {11-5846/TP},
  abstract = {混合现实技术与虚拟现实技术的进展,受到全球各界的广泛关注,并迅速引发了在教育、医疗、游戏等各个领域对未来的展望.混合现实旨在将虚拟世界与现实世界融为一体,由于其视觉景象是视点依赖的,因此穿戴式头盔显示器提供了可沉浸式观察混合现实场景的基础工具,并由计算机提供与用户观察适配的虚实融合景象.然而,虚实融合景象的生成,本质上是相异时空场景的相互嵌入,依赖于空间几何与光照环境的共享与相互作用,即几何一致性与光照一致性;在社会学意义上是行为规范的融合,需要符合人类社会学与心理学的规律,即行为一致性.混合现实提供了用户与虚拟世界交互的自然界面,通过对人类动作和行为的理解,在现实世界的时空中搭建用户与虚拟世界的桥梁,在客观上具备对虚拟世界与现实世界联结的直观性.在此虚实混合的世界中,人类智能可以通过对虚实混合场景的观察来理解世界,通过自然交互按需驱动机器对虚拟世界施加影响,并临场获得计算机对场景或者数据的反馈,从而实现人类与计算机的沉浸式深度交互,进而实现机器智能与人类智能的深度融合.从非穿戴式到穿戴式设备实现了混合现实的沉浸感,从静态场景到有人类活动的场景实现了混合现实的社会化属性,而虚拟世界从具体场景扩展到大数据时代的数据可视化分析语义,则使混合现实成为人类智能与机器智能交互融合的平台.},
  language = {中文;},
  number = {12},
  journal = {中国科学:信息科学},
  author = {陈, 宝权 and 秦, 学英},
  year = {2016},
  keywords = {混合现实,社会化融合,虚实融合,智能融合,composition of virtual-real worlds,intelligence composition,mixed reality,social composition},
  pages = {1737-1747},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\9X9ICSED\\陈 和 秦 - 2016 - 混合现实中的虚实融合与人机智能交融.pdf}
}

@article{QinYiChongQueDingWuTiZiTaiDeBiShiJieFangFa2006,
  title = {{一种确定物体姿态的闭式解方法}},
  issn = {0254-3087},
  lccn = {11-2179/TH},
  abstract = {本文介绍了一种由三条互相垂直的直线确定三维物体相对于摄像机姿态的闭式解的新方法。这种闭式解方法计算过程简单,计算时间短。同时这种方法能够由三条互相垂直直线得到物体相对摄像机姿态的唯一解,解决了困扰姿态估计的多解问题。本文详细叙述了这种方法的求解过程,最后给出了仿真结果,证明该方法具有良好的实时性。},
  language = {中文;},
  number = {S3},
  journal = {仪器仪表学报},
  author = {秦, 丽娟 and 朱, 枫},
  year = {2006},
  keywords = {闭式解,垂直,直线,姿态估计,line perpendicular pose estimation closed-form solution},
  pages = {2211-2212+2283},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\PZYXNPX5\\秦 和 朱 - 2006 - 一种确定物体姿态的闭式解方法.pdf}
}

@article{LuShenDuJuanJiShenJingWangLuoZaiJiSuanJiShiJueZhongDeYingYongYanJiuZongShu2016,
  title = {{深度卷积神经网络在计算机视觉中的应用研究综述}},
  issn = {1004-9037},
  lccn = {32-1367/TN},
  abstract = {随着大数据时代的到来,含更多隐含层的深度卷积神经网络(Convolutional neural networks,CNNs)具有更复杂的网络结构,与传统机器学习方法相比具有更强大的特征学习和特征表达能力。使用深度学习算法训练的卷积神经网络模型自提出以来在计算机视觉领域的多个大规模识别任务上取得了令人瞩目的成绩。本文首先简要介绍深度学习和卷积神经网络的兴起与发展,概述卷积神经网络的基本模型结构、卷积特征提取和池化操作。然后综述了基于深度学习的卷积神经网络模型在图像分类、物体检测、姿态估计、图像分割和人脸识别等多个计算机视觉应用领域中的研究现状和发展趋势,主要从典型的网络结构的构建、训练方法和性能表现3个方面进行介绍。最后对目前研究中存在的一些问题进行简要的总结和讨论,并展望未来发展的新方向。},
  language = {中文;},
  number = {01},
  journal = {数据采集与处理},
  author = {卢, 宏涛 and 张, 秦川},
  year = {2016},
  keywords = {计算机视觉,卷积神经网络,目标检测,深度学习,图像识别,computer vision,convolutional neural network,deep learning,image recognition,object detection},
  pages = {1-17},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\84L4B4JW\\卢 和 张 - 2016 - 深度卷积神经网络在计算机视觉中的应用研究综述.pdf}
}

@article{YangJiYuFaXiangLiangGaiJinDeICPSuanFa2016,
  title = {{基于法向量改进的ICP算法}},
  issn = {1000-7024},
  lccn = {11-1775/TP},
  abstract = {针对三维重建领域中,不同视角下点云的多视定位和配准效率问题,提出一种基于法向量改进的ICP算法。根据点云法向量间夹角特征选出关键点,计算关键点的曲率,通过主曲率特征获取初始对应点集,用高斯曲率和点间距离双重约束查找精确匹配点对,引入平衡因子的概念,给出适用范围,在不同的点云分布下,达到最优匹配,通过四元组法计算最优刚体变换。实验结果表明,相比传统ICP算法,改进后的算法将误差降低至0.05\%,配准效率提高至70\%以上,点云配准效率明显提升。},
  language = {中文;},
  number = {01},
  journal = {计算机工程与设计},
  author = {杨, 小青 and 杨, 秋翔 and 杨, 剑},
  year = {2016},
  keywords = {点间距离,点云配准,法向量,平衡因子,曲率,balance factor,curvature,distance between points,normal vector,point cloud registration},
  pages = {169-173}
}

@article{AndersonSequenceorganizationhuman1981,
  title = {Sequence and Organization of the Human Mitochondrial Genome},
  volume = {290},
  number = {5806},
  journal = {Nature},
  author = {Anderson, Sharon and Bankier, Alan T. and Barrell, Bart G. and {de Bruijn}, Maarten HL and Coulson, Alan R. and Drouin, Jacques and Eperon, Ian C. and Nierlich, Donald P. and Roe, Bruce A. and Sanger, Frederick},
  year = {1981},
  pages = {457}
}

@article{CaiZengQiangXianShiARZaiJiaoXueZhongDeYingYongAnLiPingShu2017,
  title = {{增强现实(AR)在教学中的应用案例评述}},
  issn = {1006-9860},
  lccn = {11-3792/G4},
  abstract = {增强现实作为一种新型的手段在教育领域进行跨界融合,学习者能够在虚实融合的教学情境中,以最贴近自然的方式进行自主探索。基于增强现实的交互手段给课堂提供了新的教学方式,知识会越来越具有交互性、流动性和情境性。该文通过实证发现,大部分学生的学习态度和增强现实教具的使用是呈正相关的。当然,增强现实在教育领域的应用还处于早期阶段,在教育领域的应用既有发展机遇,也还面临着一些挑战。在未来的研究中,增强现实学习环境应该深入研究如何支持学与教,以提升学生在课堂教学中的学习效果,引领课堂教学新路向,形成教育新常态的价值诉求。},
  language = {中文;},
  number = {03},
  journal = {中国电化教育},
  author = {蔡, 苏 and 张, 晗 and 薛, 晓茹 and 王, 涛 and 王, 沛文 and 张, 泽},
  year = {2017},
  keywords = {虚拟现实,增强现实,课堂教学,AR,Augmented Reality,Classroom Teaching,Virtual Reality,VR},
  pages = {1-9+30}
}

@article{LiuARJiZhuZaiQiCheGongYeLingYuDeYingYong2017,
  title = {{AR技术在汽车工业领域的应用}},
  issn = {1674-098X},
  lccn = {11-5640/N},
  abstract = {AR(Augmented Reality)技术,即增强现实技术,通过实时计算摄影机影像的位置和角度,同时添加相对应图像并展示,此类技术可将虚拟世界叠加在实物上并展现出来,从而实现人机互动。通过AR技术进行的展示将图片、多媒体、三维建模、视频控制显示、多传感器融合、实时跟踪注册、场景融合等技术相结合,在零部件设计展示、机械零部件装配和维修、汽车驾驶及汽车销售等领域有重要的研究意义、推广价值和发展潜力。},
  language = {中文;},
  number = {19},
  journal = {科技创新导报},
  author = {刘, 思源 and 曾, 传华 and 夏, 茂栩 and 张, 一寒},
  year = {2017},
  keywords = {汽车驾驶,汽车维修,汽车销售,AR技术},
  pages = {110-111}
}

@article{JiaJiYuJiHeGuanXiYueShuDeTeZhengDianPiPeiSuanFa2015,
  title = {{基于几何关系约束的特征点匹配算法}},
  issn = {1003-9775},
  lccn = {11-2925/TP},
  abstract = {特征匹配是计算机视觉中的一个基本问题,基于特征点的特征匹配方法则是其中最为常用的一种算法,有着重要的研究意义和研究价值.众所周知,特征点匹配的结果受很多因素的影响.为更好地处理视角变换的特征匹配问题,给出一种基于特征点位置关系的几何约束匹配方法.即通过引入新近发现的射影不变量\textemdash\textemdash{}特征数,构建特征点位置间的几何信息描述子;进一步建立每个点的特征数直方图并使用巴氏系数度量几何相似度;最后在基于纹理特征描述子基础上增加文中所给出的几何信息描述子获得特征匹配的约束条件.实验结果证明,该算法可以有效的提高特征点匹配的精度,同时对视角变化较大及纹理相似的情况具有很好的匹配效果.},
  language = {中文;},
  number = {08},
  journal = {计算机辅助设计与图形学学报},
  author = {贾, 棋 and 高, 新凯 and 罗, 钟铉 and 樊, 鑫 and 郭, 禾},
  year = {2015},
  keywords = {几何约束,特征点匹配,特征数,图像匹配,characteristic number,feature points matching,geometric constraints,image matching},
  pages = {1388-1397}
}

@phdthesis{YiJiYuTeZhengDianDeTuXiangPeiZhunJiQiZaiWenXiangZhongDeYingYong2013,
  type = {{博士}},
  title = {{基于特征点的图像配准及其在稳像中的应用}},
  abstract = {图像配准是计算机视觉和计算机图形学的研究热点，其主要目的是实现同一场景在不同条件下得到的两幅或多幅航拍图像在空间位置上的对齐，它是包括数字视频、虚拟现实技术、医学图像分析、运动分析等领域的关键步骤之一。目前图像配准仍存在着诸多待解决的问题。首先由于场景图像特别是航拍遥感图像具有动态变化、亮度变化、几何变化、相似特征多、重叠区域小等特点使得在图像配准过程中匹配对过少或误匹配增多。此时，仅靠改善配准的某一个环节很难进一步提高配准精度。其次对于复杂非线性、局部形变、多模态以及3-D图像的配准，至今仍然是极富挑战性的研究领域。鉴于上述原因，本文主要以图像配准为主线，针对各个环节进行了系统和深入的研究，重点研究了如何在复杂条件下精确地提取特征点、匹配特征点以及选择映射变换模型。同时，将图像配准的研究成果应用到复杂多运动动态场景的航拍视频稳像领域中，以提高运动载体摄像的稳定性和清晰度。 	论文全面分析并定量刻画了基于灰度的特征提取、基于特征描述符的特征匹配以及基于几何不变的特征空间关系三个因素对图像配准的影响，在图像配准的各个环节提出了基于特征点的图像配准方法和基于图像配准的视频稳像方法，并通过大量实验对提出方法进行了验证。论文取得的成果和主要创新点包括： 	1.针对传统的图像配准方法在特征点检测环节有限差分近似梯度滤波器的精度较差问题，提出了一种基于优化梯度滤波的图像配准算法。研究了几种传统的基于一阶和二阶梯度滤波的特征点检测算法，并在此基础上提出一种基于优化梯度滤波的特征点检测算法，以实现特征点的精确定位，同时，为了保证在不同摄像机焦距下获得相同的特征点，保留三个分辨率下具有恒定不变的特征点；然后利用最小生成树方法(MST)对待配准点进行初始匹配；一致特征点建立后，通过利用非线性最小二乘(NLLS)和随机采样一致性(RANSAC)算法选取具有全局最小误差的变换参数对视频帧间实现配准。实验结果表明，通过利用优化梯度滤波和全局最优模型估计可实现航拍图像的精确配准，且对不同动态场景和光照变换具有较强的适应性。 	2.针对基于矩不变的图像配准算法中，特征匹配环节只比较矩向量描述符的幅值信息而忽略了相位信息，提出了一种结合矩相位信息和幅值信息的具有旋转不变性的图像配准算法。首先利用尺度不变检测子Harris-laplace检测图像中的兴趣点，计算以兴趣点为中心邻域具有尺度不变性的矩；然后利用矩向量的幅值和相角信息，通过比较每个兴趣点邻域矩向量的相似度提取出初始匹配点；并对输入图像进行几何变换后将两幅图像配准。实验结果表明，该方法对尺度、旋转以及噪声均具有鲁棒性，有效降低了误匹配的概率，实现图像的高精度配准。 	3.针对特征点检测算法得到的特征点位置发生偏移和易产生伪角点，从而导致匹配点精度不一致的问题，在映射变换模型选择环节提出了一种基于映射抑制的航拍视频配准算法。该算法可在平面背景下实现帧间的配准，并有效将目标运动和摄像机运动分离。首先利用Delaunay三角网对采集得到的特征点进行初始匹配；然后利用交比不变性方法提取精确度最高的少数匹配点，并对模型参数进行估计，完成视频帧间的配准。实验结果表明，通过利用Delaunay三角网匹配和交比不变性方法可实现帧间的精确配准，并能有效提取地面运动目标。 	4.针对大尺寸、局部非线性变化的航拍图像，提出了一种基于Delaunay三角网细分的配准技术，首先对图像提取均匀分布的特征点，通过改进的SIFT向量匹配方法获得初始匹配对；然后利用计算几何中的Delaunay三角网图分解，将大分辨率图像细分为小分辨率的对应图像。图像细分将区域间的几何差异简化为更小区域的对应问题，同时，在细分过程中设计了许多步骤去掉错误匹配对及提高点位置的精度；最后利用投影不变方法对每一区域中的匹配点进行评估，将满足投影不变的匹配点用来进行三角划分，并实现块配准。对于大尺寸或局部非线性变化图像，在常规方法无法匹配的情况下，该方法具有一定优势。 	5.深入研究与分析了电子稳像的关键技术，提出了基于3D运动模型的航拍视频稳像算法。首先，研究并分析了稳像技术的原理和方法，重点对基于图像特征的电子稳像算法流程进行了描述；然后，利用3D运动模型计算两幅图像间的摄像机运动参数；最后，在分析了Kalman滤波方法不足的基础上，提出了利用一种自适应Kalman滤波方法从全局运动矢量中精确提取扫描运动分量并进行快速运动补偿的方法。实验结果表明，该算法能够实时稳定视频帧间的抖动现象，并有效跟随场景的真实扫描。},
  language = {中文;},
  school = {西安电子科技大学},
  author = {易, 盟},
  year = {2013},
  keywords = {电子稳像,航拍图像,特征描述符,特征匹配,图像配准,Aerial image,Digital stabilization,Feature,Feature Descriptor,Image registration,Matching}
}

@article{GengJiYuTouShiBuBianErZhiTeZhengMiaoShuZiDeTuXiangPiPeiSuanFa2015,
  title = {{基于透视不变二值特征描述子的图像匹配算法}},
  issn = {1000-436X},
  lccn = {11-2102/TN},
  abstract = {针对基于局部特征的图像匹配算法普遍存在对透视变换顽健性差的缺点,提出了一种新的二值特征描述子PIBC(perspective invariant binary code),提高了图像匹配算法的透视变换顽健性。首先,在提取金字塔图像FAST特征点的基础上,利用Harris角点响应值去除非极大值点和边缘响应点;其次,通过模拟相机不同视角成像之间的透视变换,对单个FAST特征点生成不同视角变换下图像的二值描述子,使描述子具备描述不同视角图像中同一特征点的能力。实验结果表明,算法在提高描述子透视不变性的同时时间复杂度与SURF算法近似。},
  language = {中文;},
  number = {04},
  journal = {通信学报},
  author = {耿, 利川 and 苏, 松志 and 李, 绍滋},
  year = {2015},
  keywords = {图像匹配,image matching,二值特征描述子,透视不变,binary feature descriptor,perspective invariant,PIBC},
  pages = {109-118}
}

@article{GaoChangXinJiYuShenDuXueXiDeGaoFenBianLuYaoGanYingXiangMuBiaoJianCe2014,
  title = {基于深度学习的高分辨率遥感影像目标检测},
  number = {S1},
  journal = {测绘通报},
  author = {{高常鑫} and {桑农}},
  year = {2014},
  pages = {108--111},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\LCNEVQHI\\67728466504849528349485053.html}
}

@article{GuWenHuaJiYuICPPiPeiSuanFaDeShiNeiYiDongJiQiRenDingWei2013,
  title = {基于 {{ICP}} 匹配算法的室内移动机器人定位},
  number = {S1},
  journal = {华中科技大学学报: 自然科学版},
  author = {{顾文华} and {周波} and {戴先中}},
  year = {2013},
  pages = {262--266},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\D7B3UNVS\\1005563049.html}
}

@article{TekinRealTimeSeamlessSingle2017,
  title = {Real-{{Time Seamless Single Shot 6D Object Pose Prediction}}},
  journal = {arXiv preprint arXiv:1711.08848},
  author = {Tekin, Bugra and Sinha, Sudipta N. and Fua, Pascal},
  year = {2017},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\M5UXCFGF\\Tekin 等。 - 2017 - Real-Time Seamless Single Shot 6D Object Pose Pred.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\PYQ9PU76\\1711.html}
}

@inproceedings{DiasRealtimemultiobjecttracking2017,
  title = {Real-Time Multi-Object Tracking on Highly Dynamic Environments},
  booktitle = {Autonomous {{Robot Systems}} and {{Competitions}} ({{ICARSC}}), 2017 {{IEEE International Conference}} On},
  publisher = {{IEEE}},
  author = {Dias, Ricardo and Cunha, Bernardo and Sousa, Eduardo and Azevedo, Jos{\'e} Lu{\'\i}s and Silva, Jo{\~a}o and Amaral, Filipe and Lau, Nuno},
  year = {2017},
  pages = {178--183}
}

@article{ForsterSVOSemiDirectVisual,
  title = {{{SVO}}: {{Semi}}-{{Direct Visual Odometry}} for {{Monocular}} and {{Multi}}-{{Camera Systems}}},
  abstract = {Direct methods for Visual Odometry (VO) have gained popularity due to their capability to exploit information from all intensity gradients in the image. However, low computational speed as well as missing guarantees for optimality and consistency are limiting factors of direct methods, where established feature-based methods instead succeed at. Based on these considerations, we propose a Semi-direct VO (SVO) that uses direct methods to track and triangulate pixels that are characterized by high image gradients but relies on proven feature-based methods for joint optimization of structure and motion. Together with a robust probabilistic depth estimation algorithm, this enables us to efficiently track pixels lying on weak corners and edges in environments with little or high-frequency texture. We further demonstrate that the algorithm can easily be extended to multiple cameras, to track edges, to include motion priors, and to enable the use of very large field of view cameras, such as fisheye and catadioptric ones. Experimental evaluation on benchmark datasets shows that the algorithm is significantly faster than the state of the art while achieving highly competitive accuracy.},
  language = {en},
  author = {Forster, Christian and Zhang, Zichao and Gassner, Michael and Werlberger, Manuel and Scaramuzza, Davide},
  pages = {18},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\XSTRY633\\Forster 等。 - SVO Semi-Direct Visual Odometry for Monocular and.pdf}
}

@incollection{GallIntroductionRandomForests2012,
  address = {Berlin, Heidelberg},
  title = {An {{Introduction}} to {{Random Forests}} for {{Multi}}-Class {{Object Detection}}},
  volume = {7474},
  isbn = {978-3-642-34090-1 978-3-642-34091-8},
  abstract = {Object detection in large-scale real-world scenes requires efficient multi-class detection approaches. Random forests have been shown to handle large training datasets and many classes for object detection efficiently. The most prominent example is the commercial application of random forests for gaming [36]. In this chapter, we describe the general framework of random forests for multi-class object detection in images and give an overview of recent developments and implementation details that are relevant for practitioners.},
  language = {en},
  booktitle = {Outdoor and {{Large}}-{{Scale Real}}-{{World Scene Analysis}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Gall, Juergen and Razavi, Nima and Van Gool, Luc},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Dellaert, Frank and Frahm, Jan-Michael and Pollefeys, Marc and {Leal-Taix{\'e}}, Laura and Rosenhahn, Bodo},
  year = {2012},
  pages = {243-263},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\ZK262I9L\\Gall 等。 - 2012 - An Introduction to Random Forests for Multi-class .pdf},
  doi = {10.1007/978-3-642-34091-8_11}
}

@book{CriminisiDecisionforestscomputer2013,
  address = {London ; New York},
  series = {Advances in computer vision and pattern recognition},
  title = {Decision Forests for Computer Vision and Medical Image Analysis},
  isbn = {978-1-4471-4928-6 978-1-4471-4929-3},
  lccn = {TA1634 .D43 2013},
  abstract = {This practical and easy-to-follow text explores the theoretical underpinnings of decision forests, organizing the vast existing literature on the field within a new, general-purpose forest model. Topics and features: with a foreword by Prof. Y. Amit and Prof. D. Geman, recounting their participation in the development of decision forests; introduces a flexible decision forest model, capable of addressing a large and diverse set of image and video analysis tasks; investigates both the theoretical foundations and the practical implementation of decision forests.--},
  language = {en},
  publisher = {{Springer}},
  editor = {Criminisi, Antonio and Shotton, J.},
  year = {2013},
  keywords = {Computer vision,Decision trees,Diagnostic imaging,Digital techniques,Image processing},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\C6MYY2RI\\Criminisi 和 Shotton - 2013 - Decision forests for computer vision and medical i.pdf},
  note = {OCLC: ocn842841944}
}

@article{GauglitzEvaluationinterestpoint2011,
  title = {Evaluation of Interest Point Detectors and Feature Descriptors for Visual Tracking},
  volume = {94},
  number = {3},
  journal = {International journal of computer vision},
  author = {Gauglitz, Steffen and H{\"o}llerer, Tobias and Turk, Matthew},
  year = {2011},
  pages = {335},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\SDZAZ6BN\\Gauglitz 等。 - 2011 - Evaluation of interest point detectors and feature.pdf;C:\\Users\\ChenCe\\Zotero\\storage\\HKUEQ3R9\\s11263-011-0431-5.html}
}

@inproceedings{ChoiRealtime3Dobject2008,
  title = {Real-Time {{3D}} Object Pose Estimation and Tracking for Natural Landmark Based Visual Servo},
  booktitle = {Intelligent {{Robots}} and {{Systems}}, 2008. {{IROS}} 2008. {{IEEE}}/{{RSJ International Conference}} On},
  publisher = {{IEEE}},
  author = {Choi, Changhyun and Baek, Seung-Min and Lee, Sukhan},
  year = {2008},
  pages = {3983--3989},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\RT7Z532V\\4650710.html}
}

@article{YeIterativeoptimizationframebyframe2017,
  title = {Iterative Optimization for Frame-by-Frame Object Pose Tracking},
  volume = {44},
  journal = {Journal of Visual Communication and Image Representation},
  author = {Ye, Shuang and Liu, Chuancai and Li, Zhiwu and {Al-Ahmari}, Abdulrahman},
  year = {2017},
  pages = {72--81},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\KVAMX5SH\\S1047320317300172.html}
}

@incollection{KehlDeepLearningLocal2016,
  address = {Cham},
  title = {Deep {{Learning}} of {{Local RGB}}-{{D Patches}} for {{3D Object Detection}} and {{6D Pose Estimation}}},
  volume = {9907},
  isbn = {978-3-319-46486-2 978-3-319-46487-9},
  abstract = {We present a 3D object detection method that uses regressed descriptors of locally-sampled RGB-D patches for 6D vote casting. For regression, we employ a convolutional auto-encoder that has been trained on a large collection of random local patches. During testing, scene patch descriptors are matched against a database of synthetic model view patches and cast 6D object votes which are subsequently filtered to refined hypotheses. We evaluate on three datasets to show that our method generalizes well to previously unseen input data, delivers robust detection results that compete with and surpass the state-of-the-art while being scalable in the number of objects.},
  language = {en},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2016},
  publisher = {{Springer International Publishing}},
  author = {Kehl, Wadim and Milletari, Fausto and Tombari, Federico and Ilic, Slobodan and Navab, Nassir},
  editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  year = {2016},
  pages = {205-220},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\P3U2YKR4\\Kehl 等。 - 2016 - Deep Learning of Local RGB-D Patches for 3D Object.pdf},
  doi = {10.1007/978-3-319-46487-9_13}
}

@article{Linovelsystemobject2017,
  title = {A Novel System for Object Pose Estimation Using Fused Vision and Inertial Data},
  volume = {33},
  issn = {15662535},
  doi = {10.1016/j.inffus.2016.04.006},
  abstract = {Six-degree-of-freedom (6-DoF) pose estimation is of fundamental importance to many applications, such as robotics, indoor tracking and Augmented Reality. Although a number of pose estimation solutions have been proposed, it remains a critical challenge to provide a low-cost, real-time, accurate and easy-todeploy solution. Addressing this issue, this paper describes a multisensor system for accurate pose estimation that relies on low-cost technologies, in particular on a combination of webcams, inertial sensors and a printable colored fiducial. With the aid of inertial sensors, the system can estimate full pose both with monocular and stereo vision. The system error propagation is analyzed and validated by simulations and experimental tests. Our error analysis and experimental data demonstrate that the proposed system has great potential in practical applications, as it achieves high accuracy (in the order of centimeters for the position estimation and few degrees for the orientation estimation) using the mentioned low-cost sensors, while satisfying tight real-time requirements.},
  language = {en},
  journal = {Information Fusion},
  author = {Li, Juan and Besada, Juan A. and Bernardos, Ana M. and Tarr{\'\i}o, Paula and Casar, Jos{\'e} R.},
  month = jan,
  year = {2017},
  pages = {15-28},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\LJRQZLTA\\Li 等。 - 2017 - A novel system for object pose estimation using fu.pdf}
}

@inproceedings{DoumanoglouRecovering6DObject2016,
  title = {Recovering {{6D Object Pose}} and {{Predicting Next}}-{{Best}}-{{View}} in the {{Crowd}}},
  isbn = {978-1-4673-8851-1},
  doi = {10.1109/CVPR.2016.390},
  abstract = {Object detection and 6D pose estimation in the crowd (scenes with multiple object instances, severe foreground occlusions and background distractors), has become an important problem in many rapidly evolving technological areas such as robotics and augmented reality. Single shotbased 6D pose estimators with manually designed features are still unable to tackle the above challenges, motivating the research towards unsupervised feature learning and next-best-view estimation. In this work, we present a complete framework for both single shot-based 6D object pose estimation and next-best-view prediction based on Hough Forests, the state of the art object pose estimator that performs classification and regression jointly. Rather than using manually designed features we a) propose an unsupervised feature learnt from depth-invariant patches using a Sparse Autoencoder and b) offer an extensive evaluation of various state of the art features. Furthermore, taking advantage of the clustering performed in the leaf nodes of Hough Forests, we learn to estimate the reduction of uncertainty in other views, formulating the problem of selecting the next-best-view. To further improve pose estimation, we propose an improved joint registration and hypotheses verification module as a final refinement step to reject false detections. We provide two additional challenging datasets inspired from realistic scenarios to extensively evaluate the state of the art and our framework. One is related to domestic environments and the other depicts a bin-picking scenario mostly found in industrial settings. We show that our framework significantly outperforms state of the art both on public and on our datasets.},
  language = {en},
  publisher = {{IEEE}},
  author = {Doumanoglou, Andreas and Kouskouridas, Rigas and Malassiotis, Sotiris and Kim, Tae-Kyun},
  month = jun,
  year = {2016},
  pages = {3583-3592},
  file = {C:\\Users\\ChenCe\\Zotero\\storage\\2QL5RXM6\\Doumanoglou 等。 - 2016 - Recovering 6D Object Pose and Predicting Next-Best.pdf}
}


